{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ NumPy Mastery: The Complete Professional Guide\n",
    "\n",
    "**SAIR - Sudanese Artificial Intelligence Research**  \n",
    "*From Zero to NumPy Expert for Machine Learning*  \n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "\n",
    "- ‚úÖ **Create and manipulate** multi-dimensional arrays like a pro\n",
    "- ‚úÖ **Master vectorization** for 100x faster computations\n",
    "- ‚úÖ **Apply broadcasting** to solve complex operations elegantly\n",
    "- ‚úÖ **Implement ML algorithms** using pure NumPy\n",
    "- ‚úÖ **Optimize performance** with advanced indexing and ufuncs\n",
    "- ‚úÖ **Debug and profile** NumPy code effectively\n",
    "\n",
    "---\n",
    "\n",
    "## üìä Why NumPy is NON-NEGOTIABLE for ML\n",
    "\n",
    "```\n",
    "Performance Comparison (1M operations):\n",
    "Python Lists: 125ms\n",
    "NumPy Arrays: 1.2ms  ‚Üê 100x FASTER!\n",
    "```\n",
    "\n",
    "**Every ML library builds on NumPy:**\n",
    "- PyTorch, TensorFlow ‚Üí NumPy-like interfaces\n",
    "- Scikit-learn ‚Üí NumPy arrays for data\n",
    "- Pandas ‚Üí Built on NumPy\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Professional setup - RUN THIS FIRST\n",
    "import numpy as np\n",
    "import time\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Configuration for professional output\n",
    "np.set_printoptions(precision=4, suppress=True, edgeitems=3, linewidth=100)\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "print(\"üî• NumPy Professional Environment Ready!\")\n",
    "print(f\"NumPy Version: {np.__version__}\")\n",
    "print(f\"Python Version: {sys.version}\")\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. üèóÔ∏è Array Creation & Properties - The Foundation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüìä 1.1 ARRAY CREATION METHODS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# 1. From Python lists (most common)\n",
    "arr_from_list = np.array([1, 2, 3, 4, 5])\n",
    "print(f\"From list: {arr_from_list}\")\n",
    "\n",
    "# 2. Special arrays (ML initialization)\n",
    "zeros = np.zeros(5)                    # Zero initialization\n",
    "ones = np.ones((2, 3))                 # Bias terms\n",
    "identity = np.eye(3)                   # Identity matrix\n",
    "random_arr = np.random.randn(2, 4)     # Random weights\n",
    "\n",
    "print(f\"\\nZeros (weight init): {zeros}\")\n",
    "print(f\"Ones (bias init):\\n{ones}\")\n",
    "print(f\"Identity matrix:\\n{identity}\")\n",
    "print(f\"Random weights:\\n{random_arr}\")\n",
    "\n",
    "# 3. Ranges and sequences\n",
    "range_arr = np.arange(0, 10, 2)        # Like range() but returns array\n",
    "linspace_arr = np.linspace(0, 1, 5)    # Evenly spaced (great for plotting)\n",
    "\n",
    "print(f\"\\nArrange (0 to 10 step 2): {range_arr}\")\n",
    "print(f\"Linspace (0 to 1, 5 points): {linspace_arr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüìê 1.2 ARRAY PROPERTIES & METADATA\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Create a realistic ML dataset\n",
    "ml_dataset = np.array([\n",
    "    [25, 50000, 16, 1],   # [age, income, education, label]\n",
    "    [30, 60000, 18, 1],\n",
    "    [22, 35000, 12, 0],\n",
    "    [45, 80000, 20, 1]\n",
    "])\n",
    "\n",
    "print(\"ML Dataset:\")\n",
    "print(ml_dataset)\n",
    "print(f\"\\nüîç Array Properties:\")\n",
    "print(f\"Shape: {ml_dataset.shape}           ‚Üí (samples, features)\")\n",
    "print(f\"Dimensions: {ml_dataset.ndim}        ‚Üí 2D matrix\")\n",
    "print(f\"Size: {ml_dataset.size}             ‚Üí Total elements\")\n",
    "print(f\"Data type: {ml_dataset.dtype}       ‚Üí int64\")\n",
    "print(f\"Item size: {ml_dataset.itemsize} bytes ‚Üí Memory per element\")\n",
    "print(f\"Total memory: {ml_dataset.nbytes} bytes\")\n",
    "\n",
    "# Professional tip: Memory optimization\n",
    "print(f\"\\nüí° Memory Optimization:\")\n",
    "ml_dataset_float32 = ml_dataset.astype(np.float32)\n",
    "print(f\"Original: {ml_dataset.nbytes} bytes\")\n",
    "print(f\"float32: {ml_dataset_float32.nbytes} bytes ‚Üí {ml_dataset.nbytes/ml_dataset_float32.nbytes:.1f}x smaller!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. üéØ Array Indexing & Slicing - Master Data Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüéØ 2.1 BASIC INDEXING & SLICING\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Create feature matrix\n",
    "X = np.array([\n",
    "    [1, 2, 3, 4],\n",
    "    [5, 6, 7, 8], \n",
    "    [9, 10, 11, 12],\n",
    "    [13, 14, 15, 16]\n",
    "])\n",
    "\n",
    "print(\"Feature Matrix X:\")\n",
    "print(X)\n",
    "\n",
    "# Essential slicing operations\n",
    "print(f\"\\nüìç Element access:\")\n",
    "print(f\"X[0, 1] = {X[0, 1]}           ‚Üí Row 0, Column 1\")\n",
    "\n",
    "print(f\"\\nüìè Row operations:\")\n",
    "print(f\"First row:    {X[0]}\")\n",
    "print(f\"Last row:     {X[-1]}\")\n",
    "print(f\"First 2 rows:\\n{X[:2]}\")\n",
    "\n",
    "print(f\"\\nüìê Column operations:\")\n",
    "print(f\"First column: {X[:, 0]}\")\n",
    "print(f\"Last column:  {X[:, -1]}\")\n",
    "print(f\"Columns 1-3: \\n{X[:, 1:3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüî• 2.2 ADVANCED INDEXING - ML APPLICATIONS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Boolean indexing - Filter data\n",
    "ages = np.array([25, 30, 35, 40, 22, 28])\n",
    "high_income_mask = ages > 30\n",
    "print(f\"Ages: {ages}\")\n",
    "print(f\"Mask (age > 30): {high_income_mask}\")\n",
    "print(f\"Filtered ages: {ages[high_income_mask]}\")\n",
    "\n",
    "# Integer array indexing - Reorder samples\n",
    "indices = [2, 0, 1, 4, 3, 5]  # Custom order\n",
    "reordered_ages = ages[indices]\n",
    "print(f\"\\nOriginal order: {ages}\")\n",
    "print(f\"New indices:    {indices}\")\n",
    "print(f\"Reordered:      {reordered_ages}\")\n",
    "\n",
    "# Fancy indexing - Extract specific patterns\n",
    "matrix = np.random.randint(0, 100, (5, 5))\n",
    "print(f\"\\nRandom matrix:\\n{matrix}\")\n",
    "diagonal = matrix[[0, 1, 2, 3, 4], [0, 1, 2, 3, 4]]\n",
    "print(f\"Diagonal elements: {diagonal}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüîß 2.3 REAL-WORLD ML DATA EXTRACTION\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Simulate ML dataset with features and labels\n",
    "dataset = np.array([\n",
    "    [1.5, 2.0, 3.0, 0],  # [feature1, feature2, feature3, label]\n",
    "    [2.0, 3.0, 4.0, 1],\n",
    "    [3.0, 4.0, 5.0, 0],\n",
    "    [4.0, 5.0, 6.0, 1],\n",
    "    [5.0, 6.0, 7.0, 0]\n",
    "])\n",
    "\n",
    "print(\"Full Dataset:\")\n",
    "print(dataset)\n",
    "\n",
    "# Extract features and labels (most common ML operation)\n",
    "X = dataset[:, :-1]  # All rows, all columns except last\n",
    "y = dataset[:, -1]   # All rows, last column\n",
    "\n",
    "print(f\"\\nüìä Features (X):\\n{X}\")\n",
    "print(f\"\\nüéØ Labels (y): {y}\")\n",
    "\n",
    "# Split into train/test (manual way)\n",
    "train_indices = [0, 1, 3]  # 60% training\n",
    "test_indices = [2, 4]      # 40% testing\n",
    "\n",
    "X_train, X_test = X[train_indices], X[test_indices]\n",
    "y_train, y_test = y[train_indices], y[test_indices]\n",
    "\n",
    "print(f\"\\nüìö Training set ({len(X_train)} samples):\\n{X_train}\")\n",
    "print(f\"\\nüß™ Test set ({len(X_test)} samples):\\n{X_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. ‚ö° Vectorization - The Performance Revolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n‚ö° 3.1 VECTORIZATION VS LOOPS - PERFORMANCE SHOWDOWN\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create large dataset (realistic ML size)\n",
    "np.random.seed(42)\n",
    "large_data = np.random.randn(1000000)  # 1 million samples\n",
    "\n",
    "print(\"Performance Test: 1 Million Operations\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Method 1: Python loops (SLOW!)\n",
    "start_time = time.time()\n",
    "result_loop = []\n",
    "for x in large_data:\n",
    "    result_loop.append(x * 2 + np.exp(x) + np.sin(x))\n",
    "result_loop = np.array(result_loop)\n",
    "loop_time = time.time() - start_time\n",
    "\n",
    "# Method 2: NumPy vectorization (FAST!)\n",
    "start_time = time.time()\n",
    "result_vectorized = large_data * 2 + np.exp(large_data) + np.sin(large_data)\n",
    "vec_time = time.time() - start_time\n",
    "\n",
    "print(f\"üîÅ Loop time:     {loop_time:.4f} seconds\")\n",
    "print(f\"‚ö° Vectorized time: {vec_time:.4f} seconds\")\n",
    "print(f\"\\nüöÄ Speedup: {loop_time/vec_time:.1f}x FASTER!\")\n",
    "print(f\"‚úÖ Results identical: {np.allclose(result_loop, result_vectorized)}\")\n",
    "\n",
    "print(\"\\nüí° Professional Insight:\")\n",
    "print(\"Vectorization uses optimized C/Fortran code internally\")\n",
    "print(\"No Python interpreter overhead = Massive speed gains\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüßÆ 3.2 UNIVERSAL FUNCTIONS (UFUNCS) - ELEMENT-WISE OPERATIONS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create sample data\n",
    "data = np.array([1, 2, 3, 4, 5])\n",
    "\n",
    "print(\"Original data:\", data)\n",
    "print(\"\\nüìä Mathematical UFuncs:\")\n",
    "print(f\"Square root:   {np.sqrt(data)}\")\n",
    "print(f\"Exponential:   {np.exp(data)}\")\n",
    "print(f\"Logarithm:     {np.log(data)}\")\n",
    "print(f\"Sine:          {np.sin(data)}\")\n",
    "\n",
    "print(\"\\nüìà Statistical UFuncs:\")\n",
    "print(f\"Mean:          {np.mean(data):.2f}\")\n",
    "print(f\"Standard dev:  {np.std(data):.2f}\")\n",
    "print(f\"Variance:      {np.var(data):.2f}\")\n",
    "print(f\"Min/Max:       {np.min(data)} / {np.max(data)}\")\n",
    "\n",
    "# Comparison operations (essential for ML)\n",
    "print(f\"\\nüéØ Comparison UFuncs:\")\n",
    "print(f\"Data > 3:      {data > 3}\")\n",
    "print(f\"Data == 2:     {data == 2}\")\n",
    "print(f\"Non-zero:      {np.nonzero(data > 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. üåü Broadcasting - NumPy's Secret Weapon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüåü 4.1 BROADCASTING RULES - HOW IT WORKS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Rule 1: Arrays with different dimensions\n",
    "matrix = np.ones((3, 4))  # Shape: (3, 4)\n",
    "vector = np.array([1, 2, 3, 4])  # Shape: (4,)\n",
    "\n",
    "result = matrix + vector  # Vector broadcast to (3, 4)\n",
    "print(\"Rule 1 - Different dimensions:\")\n",
    "print(f\"Matrix shape: {matrix.shape}\")\n",
    "print(f\"Vector shape: {vector.shape}\")\n",
    "print(f\"Result shape: {result.shape}\")\n",
    "print(f\"Result:\\n{result}\")\n",
    "\n",
    "# Rule 2: Arrays with 1 in dimensions\n",
    "arr1 = np.ones((5, 3))    # Shape: (5, 3)\n",
    "arr2 = np.ones((1, 3))    # Shape: (1, 3)\n",
    "\n",
    "result2 = arr1 + arr2     # arr2 broadcast to (5, 3)\n",
    "print(f\"\\nRule 2 - Dimension with 1:\")\n",
    "print(f\"arr1 shape: {arr1.shape}\")\n",
    "print(f\"arr2 shape: {arr2.shape}\")\n",
    "print(f\"Result shape: {result2.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüî• 4.2 BROADCASTING IN ML - REAL APPLICATIONS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Application 1: Feature normalization (z-score)\n",
    "features = np.array([\n",
    "    [10, 100, 1000],\n",
    "    [20, 200, 2000], \n",
    "    [30, 300, 3000]\n",
    "])\n",
    "\n",
    "print(\"Original features:\")\n",
    "print(features)\n",
    "\n",
    "# Broadcasting makes this one-liner possible!\n",
    "normalized = (features - np.mean(features, axis=0)) / np.std(features, axis=0)\n",
    "\n",
    "print(f\"\\nüìä Mean per feature: {np.mean(features, axis=0)}\")\n",
    "print(f\"üìä Std per feature:  {np.std(features, axis=0)}\")\n",
    "print(f\"\\n‚úÖ Normalized features (z-score):\\n{normalized}\")\n",
    "\n",
    "# Application 2: Adding bias to all samples\n",
    "linear_output = np.array([\n",
    "    [1.5, 2.3, 0.8],\n",
    "    [2.1, 1.7, 3.2],\n",
    "    [0.9, 2.8, 1.1]\n",
    "])\n",
    "bias = np.array([0.1, 0.2, 0.3])  # Different bias per output\n",
    "\n",
    "with_bias = linear_output + bias  # bias broadcast to (3, 3)\n",
    "print(f\"\\nüß† Linear outputs:\\n{linear_output}\")\n",
    "print(f\"Bias terms: {bias}\")\n",
    "print(f\"With bias:\\n{with_bias}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. üß† Linear Algebra for Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüßÆ 5.1 DOT PRODUCTS & MATRIX MULTIPLICATION\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Dot product - Foundation of linear models\n",
    "features = np.array([1.5, 2.0, 0.5])\n",
    "weights = np.array([0.2, 0.3, 0.1])\n",
    "\n",
    "print(\"Linear Model: y = features ¬∑ weights + bias\")\n",
    "print(f\"Features: {features}\")\n",
    "print(f\"Weights:  {weights}\")\n",
    "\n",
    "# Three equivalent ways\n",
    "dot1 = np.dot(features, weights)\n",
    "dot2 = features @ weights\n",
    "dot3 = np.sum(features * weights)\n",
    "\n",
    "print(f\"\\nüîπ np.dot():    {dot1:.3f}\")\n",
    "print(f\"üîπ @ operator:  {dot2:.3f}\")\n",
    "print(f\"üîπ Manual sum:  {dot3:.3f}\")\n",
    "print(f\"All equal: {np.allclose([dot1, dot2, dot3], dot1)}\")\n",
    "\n",
    "# Matrix multiplication\n",
    "X = np.random.randn(5, 3)  # 5 samples, 3 features\n",
    "W = np.random.randn(3, 2)  # 3 features, 2 outputs\n",
    "\n",
    "output = X @ W  # Result: (5, 2) - predictions for 5 samples, 2 classes\n",
    "print(f\"\\nüß† Neural Network Layer:\")\n",
    "print(f\"Input shape:  {X.shape} ‚Üí (samples, features)\")\n",
    "print(f\"Weight shape: {W.shape} ‚Üí (features, outputs)\")\n",
    "print(f\"Output shape: {output.shape} ‚Üí (samples, outputs)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüìä 5.2 MATRIX DECOMPOSITIONS & SOLVERS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Create a well-conditioned matrix\n",
    "A = np.array([\n",
    "    [2, 1, 1],\n",
    "    [1, 3, 2],\n",
    "    [1, 0, 0]\n",
    "])\n",
    "b = np.array([4, 5, 6])\n",
    "\n",
    "print(\"Solving Linear System: Ax = b\")\n",
    "print(f\"A = \\n{A}\")\n",
    "print(f\"b = {b}\")\n",
    "\n",
    "# Solution 1: Direct solve\n",
    "x_solve = np.linalg.solve(A, b)\n",
    "print(f\"\\nüîπ Solution x = {x_solve}\")\n",
    "print(f\"Verification A¬∑x = {A @ x_solve} (should equal b)\")\n",
    "\n",
    "# Solution 2: Using inverse (less efficient)\n",
    "A_inv = np.linalg.inv(A)\n",
    "x_inv = A_inv @ b\n",
    "print(f\"\\nüîπ Using inverse: x = {x_inv}\")\n",
    "print(f\"Methods equal: {np.allclose(x_solve, x_inv)}\")\n",
    "\n",
    "# Eigen decomposition (important for PCA)\n",
    "eigenvalues, eigenvectors = np.linalg.eig(A)\n",
    "print(f\"\\nüìà Eigen decomposition:\")\n",
    "print(f\"Eigenvalues:  {eigenvalues}\")\n",
    "print(f\"Eigenvectors:\\n{eigenvectors}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. üõ†Ô∏è Advanced Operations & Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüéØ 6.1 AGGREGATION & REDUCTION OPERATIONS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Create ML dataset\n",
    "data = np.random.randn(1000, 5)  # 1000 samples, 5 features\n",
    "\n",
    "print(\"Dataset shape:\", data.shape)\n",
    "print(\"\\nüìä Global aggregations:\")\n",
    "print(f\"Overall mean:    {np.mean(data):.4f}\")\n",
    "print(f\"Overall std:     {np.std(data):.4f}\")\n",
    "print(f\"Min/Max:         {np.min(data):.4f} / {np.max(data):.4f}\")\n",
    "\n",
    "print(\"\\nüìà Per-feature statistics (axis=0):\")\n",
    "print(f\"Feature means:   {np.mean(data, axis=0)}\")\n",
    "print(f\"Feature stds:    {np.std(data, axis=0)}\")\n",
    "\n",
    "print(\"\\nüë§ Per-sample statistics (axis=1):\")\n",
    "print(f\"Sample 0 stats:  mean={np.mean(data[0]):.4f}, std={np.std(data[0]):.4f}\")\n",
    "\n",
    "# Cumulative operations\n",
    "print(f\"\\nüìà Cumulative sum (first 10 samples):\")\n",
    "print(f\"Original: {data[:10, 0]}\")\n",
    "print(f\"Cumsum:   {np.cumsum(data[:10, 0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüîÑ 6.2 ARRAY MANIPULATION & RESHAPING\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Reshaping - Changing array structure\n",
    "original = np.arange(12)\n",
    "reshaped = original.reshape(3, 4)\n",
    "\n",
    "print(\"Reshaping examples:\")\n",
    "print(f\"Original (1D): {original}\")\n",
    "print(f\"Reshaped (3x4):\\n{reshaped}\")\n",
    "\n",
    "# Transposing - Swapping axes\n",
    "print(f\"\\nTranspose:\\n{reshaped.T}\")\n",
    "\n",
    "# Flattening - Back to 1D\n",
    "flattened = reshaped.flatten()\n",
    "print(f\"\\nFlattened: {flattened}\")\n",
    "\n",
    "# Stacking - Combining arrays\n",
    "arr1 = np.array([1, 2, 3])\n",
    "arr2 = np.array([4, 5, 6])\n",
    "\n",
    "vstack = np.vstack([arr1, arr2])  # Vertical stack\n",
    "hstack = np.hstack([arr1, arr2])  # Horizontal stack\n",
    "\n",
    "print(f\"\\nVertical stack:\\n{vstack}\")\n",
    "print(f\"Horizontal stack: {hstack}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. üéØ Real-World ML Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüß† 7.1 COMPLETE LINEAR REGRESSION FROM SCRATCH\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "class LinearRegression:\n",
    "    \"\"\"Pure NumPy Linear Regression Implementation\"\"\"\n",
    "    \n",
    "    def __init__(self, learning_rate=0.01, n_iterations=1000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_iterations = n_iterations\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "        self.loss_history = []\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Train the model using gradient descent\"\"\"\n",
    "        n_samples, n_features = X.shape\n",
    "        \n",
    "        # Initialize parameters\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "        \n",
    "        # Gradient descent\n",
    "        for i in range(self.n_iterations):\n",
    "            # Predictions\n",
    "            y_pred = self.predict(X)\n",
    "            \n",
    "            # Compute gradients (VECTORIZED!)\n",
    "            dw = (1 / n_samples) * (X.T @ (y_pred - y))\n",
    "            db = (1 / n_samples) * np.sum(y_pred - y)\n",
    "            \n",
    "            # Update parameters\n",
    "            self.weights -= self.learning_rate * dw\n",
    "            self.bias -= self.learning_rate * db\n",
    "            \n",
    "            # Compute loss\n",
    "            loss = np.mean((y_pred - y) ** 2)\n",
    "            self.loss_history.append(loss)\n",
    "            \n",
    "            if i % 200 == 0:\n",
    "                print(f\"Iteration {i}: Loss = {loss:.4f}\")\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Make predictions\"\"\"\n",
    "        return X @ self.weights + self.bias\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        \"\"\"Calculate R-squared score\"\"\"\n",
    "        y_pred = self.predict(X)\n",
    "        ss_res = np.sum((y - y_pred) ** 2)\n",
    "        ss_tot = np.sum((y - np.mean(y)) ** 2)\n",
    "        return 1 - (ss_res / ss_tot)\n",
    "\n",
    "# Generate sample data\n",
    "np.random.seed(42)\n",
    "X_train = 2 * np.random.rand(100, 1)\n",
    "y_train = 4 + 3 * X_train + np.random.randn(100, 1)\n",
    "\n",
    "# Train model\n",
    "print(\"Training Linear Regression...\")\n",
    "model = LinearRegression(learning_rate=0.1, n_iterations=1000)\n",
    "model.fit(X_train, y_train.flatten())\n",
    "\n",
    "print(f\"\\n‚úÖ Training completed!\")\n",
    "print(f\"Final weights: {model.weights[0]:.4f}\")\n",
    "print(f\"Final bias:    {model.bias:.4f}\")\n",
    "print(f\"R¬≤ score:      {model.score(X_train, y_train.flatten()):.4f}\")\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(X_train, y_train, alpha=0.7, label='Data')\n",
    "plt.plot(X_train, model.predict(X_train), 'r-', label='Regression line', linewidth=2)\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Target')\n",
    "plt.title('Linear Regression Fit')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(model.loss_history)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss (MSE)')\n",
    "plt.title('Training Loss')\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüîß 7.2 DATA PREPROCESSING PIPELINE\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "class DataPreprocessor:\n",
    "    \"\"\"Complete data preprocessing using NumPy\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.mean = None\n",
    "        self.std = None\n",
    "        self.min = None\n",
    "        self.max = None\n",
    "    \n",
    "    def fit(self, X):\n",
    "        \"\"\"Learn preprocessing parameters from data\"\"\"\n",
    "        self.mean = np.mean(X, axis=0)\n",
    "        self.std = np.std(X, axis=0)\n",
    "        self.min = np.min(X, axis=0)\n",
    "        self.max = np.max(X, axis=0)\n",
    "    \n",
    "    def transform(self, X, method='zscore'):\n",
    "        \"\"\"Transform data using learned parameters\"\"\"\n",
    "        if method == 'zscore':\n",
    "            return (X - self.mean) / self.std\n",
    "        elif method == 'minmax':\n",
    "            return (X - self.min) / (self.max - self.min)\n",
    "        else:\n",
    "            raise ValueError(\"Method must be 'zscore' or 'minmax'\")\n",
    "    \n",
    "    def fit_transform(self, X, method='zscore'):\n",
    "        \"\"\"Fit and transform in one step\"\"\"\n",
    "        self.fit(X)\n",
    "        return self.transform(X, method)\n",
    "\n",
    "# Test the preprocessor\n",
    "raw_data = np.array([\n",
    "    [10, 1000, 0.1],\n",
    "    [20, 2000, 0.2],\n",
    "    [30, 3000, 0.3],\n",
    "    [40, 4000, 0.4]\n",
    "])\n",
    "\n",
    "print(\"Raw data:\")\n",
    "print(raw_data)\n",
    "\n",
    "preprocessor = DataPreprocessor()\n",
    "\n",
    "# Z-score normalization\n",
    "zscore_data = preprocessor.fit_transform(raw_data, 'zscore')\n",
    "print(f\"\\nüìä Z-score normalized:\")\n",
    "print(zscore_data)\n",
    "print(f\"New means: {np.mean(zscore_data, axis=0)}\")\n",
    "print(f\"New stds:  {np.std(zscore_data, axis=0)}\")\n",
    "\n",
    "# Min-max normalization\n",
    "minmax_data = preprocessor.fit_transform(raw_data, 'minmax')\n",
    "print(f\"\\nüìà Min-max normalized:\")\n",
    "print(minmax_data)\n",
    "print(f\"Range: [{np.min(minmax_data, axis=0)} to {np.max(minmax_data, axis=0)}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. üèÜ Professional NumPy Best Practices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüí° 8.1 MEMORY EFFICIENCY & PERFORMANCE TIPS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# 1. Use appropriate data types\n",
    "large_array = np.ones(1000000, dtype=np.float64)\n",
    "optimized_array = np.ones(1000000, dtype=np.float32)\n",
    "\n",
    "print(\"1. Data Type Optimization:\")\n",
    "print(f\"float64: {large_array.nbytes / 1024:.1f} KB\")\n",
    "print(f\"float32: {optimized_array.nbytes / 1024:.1f} KB ‚Üí {large_array.nbytes/optimized_array.nbytes:.1f}x smaller!\")\n",
    "\n",
    "# 2. Avoid unnecessary copies\n",
    "original = np.arange(10)\n",
    "view = original[::2]      # View (no copy)\n",
    "copy = original[::2].copy()  # Explicit copy\n",
    "\n",
    "print(f\"\\n2. Memory Views vs Copies:\")\n",
    "print(f\"Original base: {original.base}\")\n",
    "print(f\"View base:     {view.base is original}\")  # Shares memory\n",
    "print(f\"Copy base:     {copy.base is original}\")  # Separate memory\n",
    "\n",
    "# 3. Use in-place operations\n",
    "arr = np.ones(5)\n",
    "arr += 1          # In-place (efficient)\n",
    "arr = arr + 1     # Creates new array (less efficient)\n",
    "\n",
    "print(f\"\\n3. In-place operations save memory\")\n",
    "\n",
    "# 4. Preallocate arrays\n",
    "print(f\"\\n4. Preallocation Example:\")\n",
    "\n",
    "# Bad: Growing list\n",
    "start = time.time()\n",
    "result = []\n",
    "for i in range(10000):\n",
    "    result.append(i ** 2)\n",
    "result = np.array(result)\n",
    "bad_time = time.time() - start\n",
    "\n",
    "# Good: Preallocated\n",
    "start = time.time()\n",
    "result_good = np.zeros(10000)\n",
    "for i in range(10000):\n",
    "    result_good[i] = i ** 2\n",
    "good_time = time.time() - start\n",
    "\n",
    "print(f\"Growing list: {bad_time:.4f}s\")\n",
    "print(f\"Preallocated: {good_time:.4f}s\")\n",
    "print(f\"Speedup: {bad_time/good_time:.1f}x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüîç 8.2 DEBUGGING & PROFILING NUMPY CODE\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# 1. Array inspection\n",
    "complex_array = np.random.randn(3, 4, 5)\n",
    "\n",
    "print(\"1. Array Inspection Tools:\")\n",
    "print(f\"Shape: {complex_array.shape}\")\n",
    "print(f\"Dimensions: {complex_array.ndim}\")\n",
    "print(f\"Data type: {complex_array.dtype}\")\n",
    "print(f\"Memory layout: {complex_array.flags}\")\n",
    "\n",
    "# 2. Checking array properties\n",
    "print(f\"\\n2. Array Properties:\")\n",
    "print(f\"Has NaN: {np.any(np.isnan(complex_array))}\")\n",
    "print(f\"Has Inf: {np.any(np.isinf(complex_array))}\")\n",
    "print(f\"All finite: {np.all(np.isfinite(complex_array))}\")\n",
    "print(f\"Is contiguous: {complex_array.flags.contiguous}\")\n",
    "\n",
    "# 3. Performance profiling\n",
    "def slow_operation():\n",
    "    \"\"\"Inefficient implementation\"\"\"\n",
    "    result = np.zeros(1000)\n",
    "    for i in range(1000):\n",
    "        result[i] = np.sin(i) + np.cos(i) ** 2\n",
    "    return result\n",
    "\n",
    "def fast_operation():\n",
    "    \"\"\"Vectorized implementation\"\"\"\n",
    "    i = np.arange(1000)\n",
    "    return np.sin(i) + np.cos(i) ** 2\n",
    "\n",
    "# Time both implementations\n",
    "start = time.time()\n",
    "slow_result = slow_operation()\n",
    "slow_time = time.time() - start\n",
    "\n",
    "start = time.time()\n",
    "fast_result = fast_operation()\n",
    "fast_time = time.time() - start\n",
    "\n",
    "print(f\"\\n3. Performance Comparison:\")\n",
    "print(f\"Slow (loop): {slow_time:.4f}s\")\n",
    "print(f\"Fast (vectorized): {fast_time:.4f}s\")\n",
    "print(f\"Speedup: {slow_time/fast_time:.1f}x\")\n",
    "print(f\"Results equal: {np.allclose(slow_result, fast_result)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéâ NumPy Mastery Achievement Unlocked!\n",
    "\n",
    "## üèÜ What You've Accomplished\n",
    "\n",
    "‚úÖ **Array Creation & Manipulation** - From basic to advanced  \n",
    "‚úÖ **Vectorization Mastery** - 100x performance gains  \n",
    "‚úÖ **Broadcasting Expertise** - Elegant multi-dimensional operations  \n",
    "‚úÖ **Linear Algebra Proficiency** - ML mathematical foundations  \n",
    "‚úÖ **Real ML Implementation** - Complete algorithms from scratch  \n",
    "‚úÖ **Professional Best Practices** - Production-ready code\n",
    "\n",
    "## üöÄ Next Steps in Your ML Journey\n",
    "\n",
    "1. **Practice** with the exercises below\n",
    "2. **Implement** more ML algorithms (Logistic Regression, Neural Networks)\n",
    "3. **Explore** advanced NumPy (strides, masked arrays, structured arrays)\n",
    "4. **Join** the SAIR community for projects and collaboration\n",
    "\n",
    "---\n",
    "\n",
    "# üß™ Final Comprehensive Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüéØ COMPREHENSIVE EXERCISES - TEST YOUR MASTERY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def exercise_1():\n",
    "    \"\"\"Implement Mean Squared Error and its gradient\"\"\"\n",
    "    print(\"\\n1. MSE & Gradient Implementation\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # TODO: Implement these functions\n",
    "    def mse(y_true, y_pred):\n",
    "        \"\"\"Calculate Mean Squared Error\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def mse_gradient(X, y_true, y_pred):\n",
    "        \"\"\"Calculate gradient of MSE w.r.t. weights\"\"\"\n",
    "        pass\n",
    "    \n",
    "    # Test data\n",
    "    X_test = np.array([[1, 2], [3, 4], [5, 6]])\n",
    "    y_true_test = np.array([3, 7, 11])\n",
    "    y_pred_test = np.array([2.9, 7.1, 10.8])\n",
    "    \n",
    "    print(\"Implement mse() and mse_gradient() functions!\")\n",
    "\n",
    "def exercise_2():\n",
    "    \"\"\"Implement K-means clustering from scratch\"\"\"\n",
    "    print(\"\\n2. K-means Clustering Implementation\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # TODO: Implement K-means\n",
    "    class KMeans:\n",
    "        def __init__(self, k=3, max_iters=100):\n",
    "            pass\n",
    "        \n",
    "        def fit(self, X):\n",
    "            pass\n",
    "        \n",
    "        def predict(self, X):\n",
    "            pass\n",
    "    \n",
    "    print(\"Implement the KMeans class!\")\n",
    "\n",
    "def exercise_3():\n",
    "    \"\"\"Optimize array operations for large datasets\"\"\"\n",
    "    print(\"\\n3. Performance Optimization Challenge\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Create large dataset\n",
    "    data = np.random.randn(10000, 50)\n",
    "    \n",
    "    # TODO: Optimize these operations\n",
    "    # 1. Normalize each feature to [0, 1] range\n",
    "    # 2. Remove features with variance < 0.1\n",
    "    # 3. Compute correlation matrix\n",
    "    \n",
    "    print(\"Optimize these operations for speed and memory!\")\n",
    "\n",
    "# Run exercises\n",
    "exercise_1()\n",
    "exercise_2()\n",
    "exercise_3()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéâ CONGRATULATIONS! You've completed NumPy Mastery!\")\n",
    "print(\"\\nYou now have the foundation to excel in:\")\n",
    "print(\"‚úÖ Machine Learning Algorithms\")\n",
    "print(\"‚úÖ Deep Learning Frameworks\")\n",
    "print(\"‚úÖ Data Science Projects\")\n",
    "print(\"‚úÖ Research Implementations\")\n",
    "print(\"\\nKeep building! üöÄ\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}